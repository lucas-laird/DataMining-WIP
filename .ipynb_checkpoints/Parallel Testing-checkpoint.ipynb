{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from networkx.algorithms.shortest_paths.generic import shortest_path_length\n",
    "from multiprocessing import Pool, Manager,cpu_count\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        doc = f.read()\n",
    "        reviews = doc.split('<EOR>')\n",
    "    data = [];\n",
    "    for r in reviews:\n",
    "        temp = re.sub(r'([^\\s\\w]|_)+', '', r)\n",
    "        temp = temp.split()\n",
    "        temp = list(filter(lambda a: a != '', temp))\n",
    "        temp = [t.lower() for t in temp]\n",
    "        data.append(temp)\n",
    "    return(data)\n",
    "def read_directory(directory):\n",
    "    data = []\n",
    "    id_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            business_id = filename.split('.txt')[0]\n",
    "            filename = directory + '/' + filename\n",
    "            temp = read_file(filename)\n",
    "            for t in temp: \n",
    "                data.append(t)\n",
    "                id_list.append(business_id)\n",
    "    return((data,id_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_graph_parallel(data, num_p = -1):\n",
    "    G = nx.Graph()\n",
    "    if num_p == -1:\n",
    "        num_p = cpu_count()\n",
    "    pool = Pool(num_p)\n",
    "    results = pool.map(gen_smallGraph, data)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for r in results:\n",
    "        G = nx.compose(G,r)\n",
    "    largest_cc = max(nx.connected_components(G), key = len)\n",
    "    G = G.subgraph(largest_cc)\n",
    "    return(G)\n",
    "\n",
    "def gen_smallGraph(review):\n",
    "    G = nx.Graph()\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    prev_word = None\n",
    "    for word in s:\n",
    "        if not word in stopWords:\n",
    "            if not word.isnumeric():\n",
    "                if len(word) >= 3:\n",
    "                    if not word in list(G.nodes):\n",
    "                        G.add_node(word)\n",
    "                    if prev_word:\n",
    "                        if not (prev_word,word) in list(G.edges):\n",
    "                            G.add_edge(prev_word,word)\n",
    "                    prev_word = word\n",
    "            else:\n",
    "                if not word in list(G.nodes):\n",
    "                        G.add_node(word)\n",
    "                if prev_word:\n",
    "                    if not (prev_word,word) in list(G.edges):\n",
    "                        G.add_edge(prev_word,word)\n",
    "                prev_word = word\n",
    "    return(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findResSet(T):\n",
    "    degs = T.degree()\n",
    "    root = 0\n",
    "    path = -1\n",
    "    for k in degs:\n",
    "        if k[1] > 1: root = k[0]\n",
    "        if k[1] > 2:\n",
    "            path = -1\n",
    "            break\n",
    "        if k[1] <= 1: path = k[0]\n",
    "    if path != -1: return ({}, [path])\n",
    "\n",
    "    (L, um, _) = partitionLeaves(T, node=root)\n",
    "    R = []\n",
    "    for h in L:\n",
    "        if len(L[h]) > 0:\n",
    "            i = np.random.choice(len(L[h]))\n",
    "            R.extend(L[h][:i] + L[h][i+1:])\n",
    "    return (L, R)\n",
    "\n",
    "def partitionLeaves(T, node=0,  parent=-1):\n",
    "    (marked, unmarked, last) = ({}, [], -1)\n",
    "    N = T.degree(node)\n",
    "    if N == 1: return (marked, [node], last)\n",
    "    if N >= 3:\n",
    "        marked[node] = []\n",
    "        last = node\n",
    "    children = [n for n in T.neighbors(node) if n!=parent]\n",
    "    for child in children:\n",
    "        (m, um, l) = partitionLeaves(T, node=child, parent=node)\n",
    "        marked.update(m)\n",
    "        if len(um) > 0 and N >= 3: marked[node].extend(um)\n",
    "        else:\n",
    "            unmarked.extend(um)\n",
    "            last = l \n",
    "    if len(unmarked) > 0 and last != -1: marked[last].extend(unmarked)\n",
    "    return (marked, unmarked, last)\n",
    "\n",
    "#Intersect multiple spanning tree approach\n",
    "def find_trees(G,root):\n",
    "    btree = nx.bfs_tree(G,source = root)\n",
    "    dtree = nx.dfs_tree(G,source = root)\n",
    "    btree = btree.to_undirected()\n",
    "    dtree = dtree.to_undirected()\n",
    "    return(btree,dtree)\n",
    "\n",
    "def gen_trees_sets(G, num_trees = 1, union = False):\n",
    "    roots = np.random.choice(list(G.nodes), num_trees, replace = False)\n",
    "    res_set = None\n",
    "    for root in roots:\n",
    "        btree = nx.bfs_tree(G,source = root)\n",
    "        btree = btree.to_undirected()\n",
    "        L,R = findResSet(btree)\n",
    "        R = set(R)\n",
    "        if res_set:\n",
    "            if union:\n",
    "                res_set = res_set | R\n",
    "            else:\n",
    "                res_set = res_set & R\n",
    "        else:\n",
    "            res_set = R\n",
    "    return(list(res_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distanceMatrix(G, R = None):\n",
    "    if(R):\n",
    "        #set up so that resolving set R will be column labels and rest of graph will be rows\n",
    "        dist = {}\n",
    "        for r in R:\n",
    "            dist.update({r : dict(shortest_path_length(G,source = r))})\n",
    "    else:\n",
    "        dist = dict(shortest_path_length(G))\n",
    "    dist_mat = pd.DataFrame.from_dict(dist)\n",
    "    return(dist_mat)\n",
    "    \n",
    "def prune_ResSet(G,R):\n",
    "    M = distanceMatrix(G,R = R)\n",
    "    M_backup = M\n",
    "    M.drop(index = R) #Remove resolving set from check since we know those will be resolved\n",
    "    i = 0\n",
    "    np.random.shuffle(R) #Shuffle R\n",
    "    is_resolving = True\n",
    "    while is_resolving:\n",
    "        print(\"iteration {}. Size of Resolving set {}\".format(i,len(R)))\n",
    "        r = R[i]\n",
    "        i = i+1\n",
    "        M.drop(columns = r)#Remove node from resolving set\n",
    "        is_resolving = checkResolving_parallel(M)\n",
    "        if is_resolving:\n",
    "            R.remove(r)\n",
    "    return(R)\n",
    "        \n",
    "def checkColumn_parallel(ns,i):\n",
    "    n = ns.df.shape[0]\n",
    "    for j in range(i+1,n):\n",
    "        if all(ns.df.iloc[i,:] == ns.df.iloc[j,:]):\n",
    "            return(False)\n",
    "        return(True)\n",
    "    \n",
    "def checkResolving_parallel(M, num_p = -1):\n",
    "    n = M.shape[0]\n",
    "    if num_p == -1:\n",
    "        num_p = cpu_count()\n",
    "    p = Pool(num_p)\n",
    "    mgr = Manager()\n",
    "    ns = mgr.Namespace()\n",
    "    ns.df = M\n",
    "    results = p.map(checkColumn_parallel, [(ns,i) for i in range(n-1)])\n",
    "    p.close()\n",
    "    p.join()\n",
    "    if all(results):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
